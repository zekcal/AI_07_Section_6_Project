# Meme_Style_Sentence_Generater
#### 1. 프로젝트 개요 : 어투별 문장 생성기
인터넷에서 성경 어투로 햄버거를 사먹는 모습을 묘사한 글이 밈으로 소비되는 것을 보고, **밈에서 사용된 어투의 문장 생성기**를 만들고 배포하면 사이트 이용자를 모을 수 있을 것이며 이를 통해 광고비 확보 등의 성과를 만들 수 있을 것이라 생각해 프로젝트를 진행함
- 데이터는 크게 3가지로, 각각 저작권이 만료된 txt 형태의 성경, AI HUB를 통해 확보한 json 형태의 판결문, 스트리밍 방식으로 '올림픽'을 트위터에 검색해 확보한 트윗임


#### 2. 프로젝트 진행 과정
데이터 수집 - 전처리 및 토큰화 후 데이터 분석 - 사전학습된 모델을 활용한 딥 러닝
- **데이터 수집**
  - 성경의 경우 웹에서 저작권이 만료된 txt 형태의 파일을 발견해 로컬에 저장함
  - 판결문의 경우 AI HUB를 통해 저작권 문제가 없는  json 형태의 파일을 확보해 로컬에 저장함
  - 트위터의 경우 스트리밍을 사용해 프로젝트 진행 당시 가장 큰 주제였던 '올림픽'을 트위터 검색창에 입력하고 나오는 트윗들을 취합해 15,000여 줄의 데이터를 확보해 로컬에 저장함
    - API의 한계로 7일 이전의 트윗들은 불러올 수 없었고, 외부 패키지 역시 API 구조의 변경으로 인해 더 이상 사용할 수 없어 이 방식을 택함

- **전처리 및 토큰화 후 데이터 분석**
  - 링크 주소, @아이디 형태의 맨션, RT 제거, 특수문자 제거 등의 전처리를 진행
  - konlpy 패키지 중 okt를 선택해 토큰화를 진행함
  - 단어에서 의미가 있는 부분과 없는 부분을 나누어 사용 빈도와 사용율을 그래프화해 분석함
    - 의미있는 부분(이하 어간)의 경우 트위터가 가장 밀집되게 사용했고 판결문이 가장 골고루 사용함
      - 트위터 데이터 특성상 올림픽을 검색어로 하여 대부분의 문장에 올림픽이 포함되어 발생한 결과로 추정
    - 어간의 경우 그래프의 기울기가 트위터보다 성경과 판결문이 가파름
      - 판결문과 성경은 한정된 어간이 반복적으로 다른 문장에도 쓰여서 단조롭다는 것을 보여줌
      - 트위터는 올림픽에도 불구하고 일상언어에 가깝기 때문에 어간의 범위가 넓음
    - 의미없는 부분(이하 어미)의 경우 판결문이 가장 밀집된 어미를 사용했고 트위터가 가장 분포된 어미를 사용함
      - 판결문의 경우 대부분의 문장이 딱딱하고 유사한 구조로 되어 있기 때문에 이런 결과가 나온 것으로 추정
    - 어미의 경우 그래프의 기울기가 트위터보다 성경과 판결문이 가파름
      - 트위터가 가장 다양한 어미를 사용하고 다른 둘은  그렇지 아니하기 때문으로 추정

- **사전학습된 모델을 활용한 딥 러닝**
  - 로컬 환경과 colab을 활용해 KOGPT2 사전 학습 모델을 통해 딥 러닝을 진행함
  - 상황의 한계로 인해 epoch 5로 제한적인 횟수만 학습을 완료함

#### 3. 결론
사전 학습 모델을 활용해 밈의 어투를 가진 문장을 빠르게 생성할 수 있으며 밈이 변하더라도 반복하여 사용할 수 있음

#### 4. 파일 구성
폴더 .git.bfg-report/2022-02-17/23-28-23 : 대용량 파일을 업로드하는 과정에서 사용된 폴더  
폴더 .ipynb_checkpoints : ipynb 파일의 자동 저장 내용이 들어있는 폴더  
폴더 pycache : python파일을 사용하면 생기는, 더 빠르게 실행하는 것을 도와주는 폴더  
폴더 static : templates를 꾸며주는 역할을 하는 폴더  
폴더 templates : 웹을 통해 들어올 때 보여주는 모습이 적힌 폴더  
.gitattributes : 대용량 파일의 깃허브 업로드 과정에서 사용된 파일  
**1_get_bible.ipynb** : 성경 데이터를 확보하는 과정을 기록한 파일  
**1_get_judge.ipynb** : 판결문 데이터를 확보하는 과정을 기록한 파일  
**1_get_tweet.ipynb** : 트위터 데이터를 확보하는 과정을 기록한 파일  
**2_get_token.ipynb** : 토큰화를 진행한 과정을 기록한 파일  
**2_token_analyze.ipynb** : 토큰화된 결과를 통해 빈도수 등을 비교해 분석한 과정을 기록한 파일  
**3_train_bible.ipynb** : KOGPT2를 활용해 성경에 대한 사전학습을 진행한 과정을 기록한 파일  
**3_train_judge.ipynb** : KOGPT2를 활용해 판결문에 대한 사전학습을 진행한 과정을 기록한 파일  
**3_train_twit.ipynb** : KOGPT2를 활용해 트위터에 대한 사전학습을 진행한 과정을 기록한 파일  
4_app.py : 배포 과정에서 실행하기 위해 준비했던 파일  
bfg-1.14.0.jar : 대용량 파일의 깃허브 업로드 과정에서 사용된 파일  
edited_bible.txt : 성경 데이터를 txt 형식으로 저장한 파일  
edited_judgement.txt : 판결문 데이터를 txt 형식으로 저장한 파일  
edited_twit.txt : 트위터 데이터를 txt 형식으로 저장한 파일  
requirements.txt : heroku를 사용하기 위한, 환경변수가 기록된 파일  

#### 5. 프로젝트 진행 기간
22.02.15 ~ 22.02.25

#### 6. 프로젝트 과정에서 느낀 것
- **주제의 잦은 변경**
    - 다양한 문제(충분한 양의 데이터를 확보하지 못함, 외부 패키지의 지원 종료, 흥미도 낮음 등)로 인해 프로젝트 주제 선정에 과한 시간을 소비함
      - 고민에 대한 데드라인을 세우고 필히 지켜야 함을 느낌
- **원했던 데이터의 확보 실패**
  - twitter의 대용량 데이터를 구하지 못함. 기존에 생각해둔 방법들이 모두 불가능해서 한정적인 시즌의 데이터만을 가져옴
    - '특정 시즌별 어투의 변화'처럼 변경해서 진행하는 방식으로 보완 가능
- **데이터베이스 적재를 실행하지 않음**
    - 최초엔 데이터를 데이터베이스에 적재하려 했음
    - 그러나 실시간 연동이 아니며 큰 데이터가 아니었기 때문에 프로젝트를 위해 속도 면에서 불필요한 과정을 넣는 것이 유의미한지 고민하다 넣지 않기로 결정
    - 그러나 경험 측면에서라면 그럼에도 불구하고 적재 및 호출 과정을 겪는 것이 바람직한 것일 수 있단 생각이 끊임없이 들었음
- **토큰화 작업에서 kkma를 쓰지 못함**
    - okt보다 더 복잡하고 세부적인 분류가 가능한 kkma를 사용하려 했으나 추정컨대 트위터 데이터의 이모지로 인해 인코딩이 불가능해서 사용하지 못함
    - 인코딩 자체에도 시간이 오래 걸리기도 해서 다른 방법을 시간 내에 찾는 것보단 단순한 Okt로 진행하기로 결정한 결정이 만족스럽지 못함
      - 트위터같은 플랫폼에서 이모지는 단순히 제거해야 하는 대상이 아니라 감정을 충분히 나타내는 도구로 쓰인다고 생각하기 때문에 처리 방법에 대한 공부가 필요함
- **딥 러닝을 진행할 때 로컬 GPU를 활용하지 못함**
  - tensorflow에서 GPU를 인식하게 하는 것을 실패함
  - GPU가 로컬 딥 러닝 속도에 큰 영향을 줌을 알기에 인식시키고 싶었으나 최종적으로 포기함
  - 해결이 빨랐다면 더 빠르고 많은 학습을 토대로 프로젝트 결과를 탄탄하게 해줬겠지만 그러지 못해 epoch를 각 5회만 시도한 점이 아쉬움
    - 프로젝트가 끝난 후 전부 재설치 및 시작을 시도할 예정이었고, 현시점 설치가 완료되었음.
- **배포를 진행하지 못함**
  - 초기 기획 단계에서 심화 목표로 배포를 생각함
  - 모델을 저장하고 불러오는 과정에서 오류가 발생해 배포는 진행하지 못했음
  - 이로 인해 기획 의도를 100% 검증할 수 없던 점이 아쉬움
    - 그러나 다음 프로젝트를 위해 너무 심화 목표 실패에 매몰되지 않은 점은 긍정적
